import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats

# å°è¯•å¯¼å…¥Plotlyç›¸å…³æ¨¡å—
try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    px = None
    go = None
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
import seaborn as sns
import matplotlib.pyplot as plt
from io import BytesIO

def data_analysis_section(df: pd.DataFrame):
    """æ•°æ®åˆ†æåŠŸèƒ½ï¼ˆåŸºç¡€ç‰ˆï¼‰"""
    import numpy as np  # ç¡®ä¿åœ¨å‡½æ•°å†…éƒ¨å¯ä»¥è®¿é—®numpy
    st.markdown('<h2 class="sub-header">æ•°æ®åˆ†æ</h2>', unsafe_allow_html=True)
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    st.markdown("### åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
    st.dataframe(df.describe(), use_container_width=True)
    
    # æ•°æ®ç±»å‹ä¿¡æ¯
    st.markdown("### æ•°æ®ç±»å‹ä¿¡æ¯")
    dtype_df = pd.DataFrame({
        'åˆ—å': df.columns,
        'æ•°æ®ç±»å‹': df.dtypes.values,
        'éç©ºå€¼æ•°é‡': df.count().values,
        'ç©ºå€¼æ•°é‡': df.isnull().sum().values,
        'ç©ºå€¼æ¯”ä¾‹': (df.isnull().sum() / len(df) * 100).round(2).astype(str) + '%'
    })
    st.dataframe(dtype_df, use_container_width=True)
    
    # æ•°æ®è´¨é‡æŠ¥å‘Š
    st.markdown("### æ•°æ®è´¨é‡æŠ¥å‘Š")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_cells = len(df) * len(df.columns)
        missing_cells = df.isnull().sum().sum()
        missing_rate = (missing_cells / total_cells) * 100
        
        st.metric(
            "æ•°æ®å®Œæ•´æ€§",
            f"{100 - missing_rate:.1f}%",
            delta=f"{missing_cells} ä¸ªç¼ºå¤±å€¼"
        )
    
    with col2:
        duplicate_rows = df.duplicated().sum()
        duplicate_rate = (duplicate_rows / len(df)) * 100
        
        st.metric(
            "æ•°æ®å”¯ä¸€æ€§",
            f"{100 - duplicate_rate:.1f}%",
            delta=f"{duplicate_rows} è¡Œé‡å¤"
        )
    
    with col3:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        outlier_count = 0
        
        for col in numeric_cols:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]
            outlier_count += len(outliers)
        
        st.metric(
            "å¼‚å¸¸å€¼æ£€æµ‹",
            f"{outlier_count} ä¸ª",
            delta="åŸºäºIQRæ–¹æ³•"
        )

def data_cleaning_section(df: pd.DataFrame):
    """æ•°æ®æ¸…æ´—åŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">ğŸ§¹ æ•°æ®æ¸…æ´—</h2>', unsafe_allow_html=True)
    
    cleaning_option = st.selectbox(
        "é€‰æ‹©æ¸…æ´—æ“ä½œ",
        ["ç¼ºå¤±å€¼å¤„ç†", "é‡å¤å€¼å¤„ç†", "å¼‚å¸¸å€¼æ£€æµ‹", "æ•°æ®ç±»å‹è½¬æ¢", "æ–‡æœ¬æ¸…æ´—"]
    )
    
    if cleaning_option == "ç¼ºå¤±å€¼å¤„ç†":
        st.markdown("### ç¼ºå¤±å€¼åˆ†æ")
        
        # æ˜¾ç¤ºç¼ºå¤±å€¼ç»Ÿè®¡
        missing_stats = df.isnull().sum()
        missing_percent = (missing_stats / len(df)) * 100
        
        missing_df = pd.DataFrame({
            'åˆ—å': missing_stats.index,
            'ç¼ºå¤±æ•°é‡': missing_stats.values,
            'ç¼ºå¤±æ¯”ä¾‹(%)': missing_percent.values
        })
        missing_df = missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > 0].sort_values('ç¼ºå¤±æ•°é‡', ascending=False)
        
        if len(missing_df) > 0:
            st.dataframe(missing_df)
            
            # ç¼ºå¤±å€¼å¯è§†åŒ–
            if PLOTLY_AVAILABLE:
                fig = px.bar(missing_df, x='åˆ—å', y='ç¼ºå¤±æ¯”ä¾‹(%)', 
                            title='å„åˆ—ç¼ºå¤±å€¼æ¯”ä¾‹')
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("âš ï¸ Plotlyæœªå®‰è£…ï¼Œæ— æ³•æ˜¾ç¤ºç¼ºå¤±å€¼å¯è§†åŒ–å›¾è¡¨")
                st.bar_chart(missing_df.set_index('åˆ—å')['ç¼ºå¤±æ¯”ä¾‹(%)'])
            
            # å¤„ç†é€‰é¡¹
            st.markdown("### ç¼ºå¤±å€¼å¤„ç†")
            
            cols_with_missing = missing_df['åˆ—å'].tolist()
            selected_cols = st.multiselect("é€‰æ‹©è¦å¤„ç†çš„åˆ—", cols_with_missing)
            
            if selected_cols:
                method = st.selectbox(
                    "é€‰æ‹©å¤„ç†æ–¹æ³•",
                    ["åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ", "ç”¨å‡å€¼å¡«å……", "ç”¨ä¸­ä½æ•°å¡«å……", "ç”¨ä¼—æ•°å¡«å……", "å‰å‘å¡«å……", "åå‘å¡«å……", "è‡ªå®šä¹‰å€¼å¡«å……"]
                )
                
                if method == "è‡ªå®šä¹‰å€¼å¡«å……":
                    fill_value = st.text_input("è¾“å…¥å¡«å……å€¼")
                
                if st.button("æ‰§è¡Œå¤„ç†"):
                    cleaned_df = df.copy()
                    
                    for col in selected_cols:
                        if method == "åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ":
                            cleaned_df = cleaned_df.dropna(subset=[col])
                        elif method == "ç”¨å‡å€¼å¡«å……" and pd.api.types.is_numeric_dtype(df[col]):
                            cleaned_df[col].fillna(df[col].mean(), inplace=True)
                        elif method == "ç”¨ä¸­ä½æ•°å¡«å……" and pd.api.types.is_numeric_dtype(df[col]):
                            cleaned_df[col].fillna(df[col].median(), inplace=True)
                        elif method == "ç”¨ä¼—æ•°å¡«å……":
                            mode_val = df[col].mode()[0] if not df[col].mode().empty else 0
                            cleaned_df[col].fillna(mode_val, inplace=True)
                        elif method == "å‰å‘å¡«å……":
                            cleaned_df[col].fillna(method='ffill', inplace=True)
                        elif method == "åå‘å¡«å……":
                            cleaned_df[col].fillna(method='bfill', inplace=True)
                        elif method == "è‡ªå®šä¹‰å€¼å¡«å……":
                            cleaned_df[col].fillna(fill_value, inplace=True)
                    
                    st.success(f"âœ… å¤„ç†å®Œæˆï¼åŸæ•°æ® {len(df)} è¡Œï¼Œå¤„ç†å {len(cleaned_df)} è¡Œ")
                    
                    # æ˜¾ç¤ºå¤„ç†ç»“æœ
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("#### å¤„ç†å‰")
                        st.write(f"ç¼ºå¤±å€¼æ€»æ•°: {df[selected_cols].isnull().sum().sum()}")
                    with col2:
                        st.markdown("#### å¤„ç†å")
                        st.write(f"ç¼ºå¤±å€¼æ€»æ•°: {cleaned_df[selected_cols].isnull().sum().sum()}")
                    
                    # ä¿å­˜åˆ°session state
                    st.session_state.cleaned_df = cleaned_df
                    
                    # ä¸‹è½½æ¸…æ´—åçš„æ•°æ®
                    csv = cleaned_df.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½æ¸…æ´—åçš„æ•°æ®",
                        data=csv,
                        file_name="cleaned_data.csv",
                        mime="text/csv"
                    )
        else:
            st.success("âœ… æ•°æ®ä¸­æ²¡æœ‰ç¼ºå¤±å€¼")
    
    elif cleaning_option == "é‡å¤å€¼å¤„ç†":
        st.markdown("### é‡å¤å€¼åˆ†æ")
        
        # æ£€æµ‹é‡å¤å€¼
        duplicates = df.duplicated()
        duplicate_count = duplicates.sum()
        
        st.metric("é‡å¤è¡Œæ•°", duplicate_count)
        st.metric("é‡å¤æ¯”ä¾‹", f"{(duplicate_count/len(df)*100):.2f}%")
        
        if duplicate_count > 0:
            st.warning(f"âš ï¸ å‘ç° {duplicate_count} è¡Œé‡å¤æ•°æ®")
            
            # æ˜¾ç¤ºé‡å¤æ•°æ®
            if st.checkbox("æ˜¾ç¤ºé‡å¤æ•°æ®"):
                duplicate_rows = df[df.duplicated(keep=False)].sort_values(df.columns.tolist())
                st.dataframe(duplicate_rows)
            
            # å¤„ç†é€‰é¡¹
            st.markdown("### é‡å¤å€¼å¤„ç†")
            
            keep_option = st.selectbox(
                "ä¿ç•™ç­–ç•¥",
                ["ä¿ç•™ç¬¬ä¸€ä¸ª", "ä¿ç•™æœ€åä¸€ä¸ª", "å…¨éƒ¨åˆ é™¤"]
            )
            
            subset_cols = st.multiselect(
                "åŸºäºç‰¹å®šåˆ—æ£€æµ‹é‡å¤ï¼ˆç•™ç©ºåˆ™åŸºäºæ‰€æœ‰åˆ—ï¼‰",
                df.columns.tolist()
            )
            
            if st.button("åˆ é™¤é‡å¤å€¼"):
                if keep_option == "ä¿ç•™ç¬¬ä¸€ä¸ª":
                    keep = 'first'
                elif keep_option == "ä¿ç•™æœ€åä¸€ä¸ª":
                    keep = 'last'
                else:
                    keep = False
                
                subset = subset_cols if subset_cols else None
                cleaned_df = df.drop_duplicates(subset=subset, keep=keep)
                
                st.success(f"âœ… å¤„ç†å®Œæˆï¼åŸæ•°æ® {len(df)} è¡Œï¼Œå¤„ç†å {len(cleaned_df)} è¡Œ")
                
                # ä¿å­˜åˆ°session state
                st.session_state.cleaned_df = cleaned_df
                
                # ä¸‹è½½æ¸…æ´—åçš„æ•°æ®
                csv = cleaned_df.to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½å»é‡åçš„æ•°æ®",
                    data=csv,
                    file_name="deduplicated_data.csv",
                    mime="text/csv"
                )
        else:
            st.success("âœ… æ•°æ®ä¸­æ²¡æœ‰é‡å¤å€¼")
    
    elif cleaning_option == "å¼‚å¸¸å€¼æ£€æµ‹":
        st.markdown("### å¼‚å¸¸å€¼æ£€æµ‹")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if not numeric_cols:
            st.warning("âš ï¸ æ²¡æœ‰æ•°å€¼åˆ—å¯ä»¥è¿›è¡Œå¼‚å¸¸å€¼æ£€æµ‹")
            return
        
        selected_col = st.selectbox("é€‰æ‹©è¦æ£€æµ‹çš„åˆ—", numeric_cols)
        
        method = st.selectbox(
            "é€‰æ‹©æ£€æµ‹æ–¹æ³•",
            ["IQRæ–¹æ³•", "Z-Scoreæ–¹æ³•", "Isolation Forest", "ç®±çº¿å›¾å¯è§†åŒ–"]
        )
        
        if method == "IQRæ–¹æ³•":
            Q1 = df[selected_col].quantile(0.25)
            Q3 = df[selected_col].quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = df[(df[selected_col] < lower_bound) | (df[selected_col] > upper_bound)]
            
            st.write(f"æ£€æµ‹åˆ° {len(outliers)} ä¸ªå¼‚å¸¸å€¼")
            st.write(f"æ­£å¸¸èŒƒå›´: [{lower_bound:.2f}, {upper_bound:.2f}]")
            
            if len(outliers) > 0:
                st.dataframe(outliers)
        
        elif method == "Z-Scoreæ–¹æ³•":
            threshold = st.slider("Z-Scoreé˜ˆå€¼", 1.0, 4.0, 3.0, 0.1)
            
            z_scores = np.abs(stats.zscore(df[selected_col].dropna()))
            outliers = df[z_scores > threshold]
            
            st.write(f"æ£€æµ‹åˆ° {len(outliers)} ä¸ªå¼‚å¸¸å€¼ï¼ˆZ-Score > {threshold}ï¼‰")
            
            if len(outliers) > 0:
                st.dataframe(outliers)
        
        elif method == "Isolation Forest":
            contamination = st.slider("å¼‚å¸¸å€¼æ¯”ä¾‹", 0.01, 0.5, 0.1, 0.01)
            
            iso_forest = IsolationForest(contamination=contamination, random_state=42)
            outlier_labels = iso_forest.fit_predict(df[[selected_col]].dropna())
            
            outliers = df[outlier_labels == -1]
            
            st.write(f"æ£€æµ‹åˆ° {len(outliers)} ä¸ªå¼‚å¸¸å€¼")
            
            if len(outliers) > 0:
                st.dataframe(outliers)
        
        elif method == "ç®±çº¿å›¾å¯è§†åŒ–":
            if PLOTLY_AVAILABLE:
                fig = px.box(df, y=selected_col, title=f"{selected_col} ç®±çº¿å›¾")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("âš ï¸ Plotlyæœªå®‰è£…ï¼Œæ— æ³•æ˜¾ç¤ºç®±çº¿å›¾")
                # ä½¿ç”¨matplotlibä½œä¸ºå¤‡é€‰
                import matplotlib.pyplot as plt
                fig, ax = plt.subplots()
                ax.boxplot(df[selected_col].dropna())
                ax.set_title(f"{selected_col} ç®±çº¿å›¾")
                st.pyplot(fig)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.markdown("### ç»Ÿè®¡ä¿¡æ¯")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æœ€å°å€¼", f"{df[selected_col].min():.2f}")
            with col2:
                st.metric("ç¬¬ä¸€å››åˆ†ä½æ•°", f"{df[selected_col].quantile(0.25):.2f}")
            with col3:
                st.metric("ä¸­ä½æ•°", f"{df[selected_col].median():.2f}")
            with col4:
                st.metric("ç¬¬ä¸‰å››åˆ†ä½æ•°", f"{df[selected_col].quantile(0.75):.2f}")

def statistical_analysis_section(df: pd.DataFrame):
    """ç»Ÿè®¡åˆ†æåŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">ç»Ÿè®¡åˆ†æ</h2>', unsafe_allow_html=True)
    
    analysis_type = st.selectbox(
        "é€‰æ‹©åˆ†æç±»å‹",
        ["æè¿°æ€§ç»Ÿè®¡", "ç›¸å…³æ€§åˆ†æ", "åˆ†å¸ƒåˆ†æ", "å‡è®¾æ£€éªŒ", "å›å½’åˆ†æ"]
    )
    
    if analysis_type == "æè¿°æ€§ç»Ÿè®¡":
        st.markdown("### æè¿°æ€§ç»Ÿè®¡")
        
        # æ•°å€¼åˆ—ç»Ÿè®¡
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if numeric_cols:
            st.markdown("#### æ•°å€¼åˆ—ç»Ÿè®¡")
            desc_stats = df[numeric_cols].describe()
            st.dataframe(desc_stats)
            
            # æ·»åŠ æ›´å¤šç»Ÿè®¡æŒ‡æ ‡
            additional_stats = pd.DataFrame({
                'ååº¦': df[numeric_cols].skew(),
                'å³°åº¦': df[numeric_cols].kurtosis(),
                'å˜å¼‚ç³»æ•°': df[numeric_cols].std() / df[numeric_cols].mean()
            })
            
            st.markdown("#### é¢å¤–ç»Ÿè®¡æŒ‡æ ‡")
            st.dataframe(additional_stats)
        
        # åˆ†ç±»åˆ—ç»Ÿè®¡
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        if categorical_cols:
            st.markdown("#### åˆ†ç±»åˆ—ç»Ÿè®¡")
            
            selected_cat_col = st.selectbox("é€‰æ‹©åˆ†ç±»åˆ—", categorical_cols)
            
            value_counts = df[selected_cat_col].value_counts()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.dataframe(value_counts)
            
            with col2:
                fig = px.pie(values=value_counts.values, names=value_counts.index,
                           title=f"{selected_cat_col} åˆ†å¸ƒ")
                st.plotly_chart(fig, use_container_width=True)
    
    elif analysis_type == "ç›¸å…³æ€§åˆ†æ":
        st.markdown("### ç›¸å…³æ€§åˆ†æ")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) < 2:
            st.warning("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—è¿›è¡Œç›¸å…³æ€§åˆ†æ")
            return
        
        # ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = df[numeric_cols].corr()
        
        # çƒ­åŠ›å›¾
        fig = px.imshow(corr_matrix, 
                       title="ç›¸å…³æ€§çƒ­åŠ›å›¾",
                       color_continuous_scale="RdBu_r",
                       aspect="auto")
        st.plotly_chart(fig, use_container_width=True)
        
        # å¼ºç›¸å…³æ€§å¯¹
        st.markdown("#### å¼ºç›¸å…³æ€§åˆ†æ")
        
        threshold = st.slider("ç›¸å…³æ€§é˜ˆå€¼", 0.5, 1.0, 0.7, 0.05)
        
        strong_corr = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) >= threshold:
                    strong_corr.append({
                        'å˜é‡1': corr_matrix.columns[i],
                        'å˜é‡2': corr_matrix.columns[j],
                        'ç›¸å…³ç³»æ•°': round(corr_val, 3),
                        'ç›¸å…³æ€§å¼ºåº¦': 'å¼º' if abs(corr_val) >= 0.8 else 'ä¸­ç­‰',
                        'ç›¸å…³æ€§æ–¹å‘': 'æ­£ç›¸å…³' if corr_val > 0 else 'è´Ÿç›¸å…³'
                    })
        
        if strong_corr:
            st.dataframe(pd.DataFrame(strong_corr))
        else:
            st.info(f"æœªå‘ç°ç›¸å…³ç³»æ•°ç»å¯¹å€¼ >= {threshold} çš„å˜é‡å¯¹")
    
    elif analysis_type == "åˆ†å¸ƒåˆ†æ":
        st.markdown("### åˆ†å¸ƒåˆ†æ")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if not numeric_cols:
            st.warning("âš ï¸ æ²¡æœ‰æ•°å€¼åˆ—å¯ä»¥è¿›è¡Œåˆ†å¸ƒåˆ†æ")
            return
        
        selected_col = st.selectbox("é€‰æ‹©è¦åˆ†æçš„åˆ—", numeric_cols)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ç›´æ–¹å›¾
            fig_hist = px.histogram(df, x=selected_col, 
                                  title=f"{selected_col} åˆ†å¸ƒç›´æ–¹å›¾",
                                  marginal="box")
            st.plotly_chart(fig_hist, use_container_width=True)
        
        with col2:
            # Q-Qå›¾
            fig_qq = go.Figure()
            
            # è®¡ç®—ç†è®ºåˆ†ä½æ•°å’Œæ ·æœ¬åˆ†ä½æ•°
            sorted_data = np.sort(df[selected_col].dropna())
            n = len(sorted_data)
            theoretical_quantiles = stats.norm.ppf(np.arange(1, n+1) / (n+1))
            
            fig_qq.add_trace(go.Scatter(
                x=theoretical_quantiles,
                y=sorted_data,
                mode='markers',
                name='æ•°æ®ç‚¹'
            ))
            
            # æ·»åŠ ç†è®ºç›´çº¿
            fig_qq.add_trace(go.Scatter(
                x=theoretical_quantiles,
                y=np.mean(sorted_data) + np.std(sorted_data) * theoretical_quantiles,
                mode='lines',
                name='ç†è®ºç›´çº¿',
                line=dict(color='red')
            ))
            
            fig_qq.update_layout(title=f"{selected_col} Q-Qå›¾",
                               xaxis_title="ç†è®ºåˆ†ä½æ•°",
                               yaxis_title="æ ·æœ¬åˆ†ä½æ•°")
            
            st.plotly_chart(fig_qq, use_container_width=True)
        
        # æ­£æ€æ€§æ£€éªŒ
        st.markdown("#### æ­£æ€æ€§æ£€éªŒ")
        
        # Shapiro-Wilkæ£€éªŒï¼ˆé€‚ç”¨äºå°æ ·æœ¬ï¼‰
        if len(df[selected_col].dropna()) <= 5000:
            shapiro_stat, shapiro_p = stats.shapiro(df[selected_col].dropna())
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Shapiro-Wilkç»Ÿè®¡é‡", f"{shapiro_stat:.4f}")
            with col2:
                st.metric("på€¼", f"{shapiro_p:.4f}")
            
            if shapiro_p > 0.05:
                st.success("âœ… æ•°æ®å¯èƒ½æœä»æ­£æ€åˆ†å¸ƒï¼ˆp > 0.05ï¼‰")
            else:
                st.warning("âš ï¸ æ•°æ®å¯èƒ½ä¸æœä»æ­£æ€åˆ†å¸ƒï¼ˆp <= 0.05ï¼‰")
        
        # Kolmogorov-Smirnovæ£€éªŒ
        ks_stat, ks_p = stats.kstest(df[selected_col].dropna(), 'norm')
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("K-Sç»Ÿè®¡é‡", f"{ks_stat:.4f}")
        with col2:
            st.metric("på€¼", f"{ks_p:.4f}")

def advanced_data_processing_section(df: pd.DataFrame):
    """é«˜çº§æ•°æ®å¤„ç†åŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">é«˜çº§æ•°æ®å¤„ç†</h2>', unsafe_allow_html=True)
    
    processing_type = st.selectbox(
        "é€‰æ‹©å¤„ç†ç±»å‹",
        ["æ•°æ®æ ‡å‡†åŒ–", "ç‰¹å¾å·¥ç¨‹", "èšç±»åˆ†æ", "ä¸»æˆåˆ†åˆ†æ", "æ•°æ®é‡‡æ ·"]
    )
    
    if processing_type == "æ•°æ®æ ‡å‡†åŒ–":
        st.markdown("### æ•°æ®æ ‡å‡†åŒ–")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if not numeric_cols:
            st.warning("âš ï¸ æ²¡æœ‰æ•°å€¼åˆ—å¯ä»¥è¿›è¡Œæ ‡å‡†åŒ–")
            return
        
        selected_cols = st.multiselect("é€‰æ‹©è¦æ ‡å‡†åŒ–çš„åˆ—", numeric_cols, default=numeric_cols)
        
        if selected_cols:
            method = st.selectbox(
                "é€‰æ‹©æ ‡å‡†åŒ–æ–¹æ³•",
                ["Z-Scoreæ ‡å‡†åŒ–", "Min-Maxæ ‡å‡†åŒ–", "Robustæ ‡å‡†åŒ–"]
            )
            
            if st.button("æ‰§è¡Œæ ‡å‡†åŒ–"):
                scaled_df = df.copy()
                
                if method == "Z-Scoreæ ‡å‡†åŒ–":
                    scaler = StandardScaler()
                    scaled_df[selected_cols] = scaler.fit_transform(df[selected_cols])
                    st.info("ä½¿ç”¨Z-Scoreæ ‡å‡†åŒ–ï¼š(x - mean) / std")
                
                elif method == "Min-Maxæ ‡å‡†åŒ–":
                    scaler = MinMaxScaler()
                    scaled_df[selected_cols] = scaler.fit_transform(df[selected_cols])
                    st.info("ä½¿ç”¨Min-Maxæ ‡å‡†åŒ–ï¼š(x - min) / (max - min)")
                
                elif method == "Robustæ ‡å‡†åŒ–":
                    from sklearn.preprocessing import RobustScaler
                    scaler = RobustScaler()
                    scaled_df[selected_cols] = scaler.fit_transform(df[selected_cols])
                    st.info("ä½¿ç”¨Robustæ ‡å‡†åŒ–ï¼š(x - median) / IQR")
                
                # æ˜¾ç¤ºæ ‡å‡†åŒ–å‰åå¯¹æ¯”
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### æ ‡å‡†åŒ–å‰")
                    st.dataframe(df[selected_cols].describe())
                
                with col2:
                    st.markdown("#### æ ‡å‡†åŒ–å")
                    st.dataframe(scaled_df[selected_cols].describe())
                
                # ä¿å­˜ç»“æœ
                st.session_state.scaled_df = scaled_df
                
                # ä¸‹è½½æ ‡å‡†åŒ–åçš„æ•°æ®
                csv = scaled_df.to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½æ ‡å‡†åŒ–æ•°æ®",
                    data=csv,
                    file_name="scaled_data.csv",
                    mime="text/csv"
                )
    
    elif processing_type == "èšç±»åˆ†æ":
        st.markdown("### èšç±»åˆ†æ")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) < 2:
            st.warning("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—è¿›è¡Œèšç±»åˆ†æ")
            return
        
        selected_cols = st.multiselect(
            "é€‰æ‹©ç”¨äºèšç±»çš„åˆ—",
            numeric_cols,
            default=numeric_cols[:min(3, len(numeric_cols))]
        )
        
        if len(selected_cols) >= 2:
            n_clusters = st.slider("èšç±»æ•°é‡", 2, 10, 3)
            
            if st.button("æ‰§è¡ŒK-Meansèšç±»"):
                # æ•°æ®é¢„å¤„ç†
                data_for_clustering = df[selected_cols].dropna()
                
                # æ ‡å‡†åŒ–
                scaler = StandardScaler()
                scaled_data = scaler.fit_transform(data_for_clustering)
                
                # K-Meansèšç±»
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                cluster_labels = kmeans.fit_predict(scaled_data)
                
                # æ·»åŠ èšç±»æ ‡ç­¾åˆ°åŸæ•°æ®
                clustered_df = data_for_clustering.copy()
                clustered_df['èšç±»æ ‡ç­¾'] = cluster_labels
                
                # æ˜¾ç¤ºèšç±»ç»“æœ
                st.markdown("#### èšç±»ç»“æœ")
                
                # èšç±»ç»Ÿè®¡
                cluster_stats = clustered_df.groupby('èšç±»æ ‡ç­¾').agg({
                    col: ['mean', 'count'] for col in selected_cols
                }).round(2)
                
                st.dataframe(cluster_stats)
                
                # å¯è§†åŒ–ï¼ˆå¦‚æœæœ‰2-3ä¸ªç‰¹å¾ï¼‰
                if len(selected_cols) == 2:
                    fig = px.scatter(
                        clustered_df,
                        x=selected_cols[0],
                        y=selected_cols[1],
                        color='èšç±»æ ‡ç­¾',
                        title="èšç±»ç»“æœå¯è§†åŒ–"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                elif len(selected_cols) >= 3:
                    fig = px.scatter_3d(
                        clustered_df,
                        x=selected_cols[0],
                        y=selected_cols[1],
                        z=selected_cols[2],
                        color='èšç±»æ ‡ç­¾',
                        title="èšç±»ç»“æœ3Då¯è§†åŒ–"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # èšç±»è¯„ä¼°
                from sklearn.metrics import silhouette_score
                silhouette_avg = silhouette_score(scaled_data, cluster_labels)
                st.metric("è½®å»“ç³»æ•°", f"{silhouette_avg:.3f}")
                
                if silhouette_avg > 0.5:
                    st.success("âœ… èšç±»æ•ˆæœè‰¯å¥½")
                elif silhouette_avg > 0.25:
                    st.warning("âš ï¸ èšç±»æ•ˆæœä¸€èˆ¬")
                else:
                    st.error("âŒ èšç±»æ•ˆæœè¾ƒå·®")
    
    elif processing_type == "ä¸»æˆåˆ†åˆ†æ":
        st.markdown("### ğŸ” ä¸»æˆåˆ†åˆ†æ (PCA)")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) < 2:
            st.warning("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—è¿›è¡ŒPCAåˆ†æ")
            return
        
        selected_cols = st.multiselect(
            "é€‰æ‹©ç”¨äºPCAçš„åˆ—",
            numeric_cols,
            default=numeric_cols
        )
        
        if len(selected_cols) >= 2:
            n_components = st.slider(
                "ä¸»æˆåˆ†æ•°é‡",
                1,
                min(len(selected_cols), len(df)),
                min(3, len(selected_cols))
            )
            
            if st.button("æ‰§è¡ŒPCAåˆ†æ"):
                # æ•°æ®é¢„å¤„ç†
                data_for_pca = df[selected_cols].dropna()
                
                # æ ‡å‡†åŒ–
                scaler = StandardScaler()
                scaled_data = scaler.fit_transform(data_for_pca)
                
                # PCA
                pca = PCA(n_components=n_components)
                pca_result = pca.fit_transform(scaled_data)
                
                # åˆ›å»ºPCAç»“æœDataFrame
                pca_df = pd.DataFrame(
                    pca_result,
                    columns=[f'PC{i+1}' for i in range(n_components)]
                )
                
                # æ˜¾ç¤ºè§£é‡Šæ–¹å·®æ¯”
                st.markdown("#### ä¸»æˆåˆ†è§£é‡Šæ–¹å·®")
                
                variance_df = pd.DataFrame({
                    'ä¸»æˆåˆ†': [f'PC{i+1}' for i in range(n_components)],
                    'è§£é‡Šæ–¹å·®æ¯”': pca.explained_variance_ratio_,
                    'ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”': np.cumsum(pca.explained_variance_ratio_)
                })
                
                st.dataframe(variance_df)
                
                # å¯è§†åŒ–è§£é‡Šæ–¹å·®
                fig = px.bar(
                    variance_df,
                    x='ä¸»æˆåˆ†',
                    y='è§£é‡Šæ–¹å·®æ¯”',
                    title="å„ä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”"
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # å¦‚æœæœ‰è‡³å°‘2ä¸ªä¸»æˆåˆ†ï¼Œæ˜¾ç¤ºæ•£ç‚¹å›¾
                if n_components >= 2:
                    fig_scatter = px.scatter(
                        pca_df,
                        x='PC1',
                        y='PC2',
                        title="å‰ä¸¤ä¸ªä¸»æˆåˆ†æ•£ç‚¹å›¾"
                    )
                    st.plotly_chart(fig_scatter, use_container_width=True)
                
                # æ˜¾ç¤ºä¸»æˆåˆ†è½½è·
                st.markdown("#### ä¸»æˆåˆ†è½½è·")
                
                loadings = pd.DataFrame(
                    pca.components_.T,
                    columns=[f'PC{i+1}' for i in range(n_components)],
                    index=selected_cols
                )
                
                st.dataframe(loadings)

def data_comparison_section(df: pd.DataFrame):
    """æ•°æ®å¯¹æ¯”åŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">æ•°æ®å¯¹æ¯”</h2>', unsafe_allow_html=True)
    
    comparison_type = st.selectbox(
        "é€‰æ‹©å¯¹æ¯”ç±»å‹",
        ["åˆ—é—´å¯¹æ¯”", "åˆ†ç»„å¯¹æ¯”", "æ—¶é—´åºåˆ—å¯¹æ¯”", "ç»Ÿè®¡å¯¹æ¯”"]
    )
    
    if comparison_type == "åˆ—é—´å¯¹æ¯”":
        st.markdown("### åˆ—é—´æ•°æ®å¯¹æ¯”")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) < 2:
            st.warning("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—è¿›è¡Œå¯¹æ¯”")
            return
        
        col1_name = st.selectbox("é€‰æ‹©ç¬¬ä¸€åˆ—", numeric_cols)
        col2_name = st.selectbox("é€‰æ‹©ç¬¬äºŒåˆ—", [col for col in numeric_cols if col != col1_name])
        
        if st.button("å¼€å§‹å¯¹æ¯”"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"#### {col1_name} ç»Ÿè®¡")
                stats1 = df[col1_name].describe()
                st.dataframe(stats1)
            
            with col2:
                st.markdown(f"#### {col2_name} ç»Ÿè®¡")
                stats2 = df[col2_name].describe()
                st.dataframe(stats2)
            
            # å¯¹æ¯”å¯è§†åŒ–
            fig = go.Figure()
            
            fig.add_trace(go.Box(
                y=df[col1_name],
                name=col1_name,
                boxpoints='outliers'
            ))
            
            fig.add_trace(go.Box(
                y=df[col2_name],
                name=col2_name,
                boxpoints='outliers'
            ))
            
            fig.update_layout(title="åˆ—é—´æ•°æ®åˆ†å¸ƒå¯¹æ¯”")
            st.plotly_chart(fig, use_container_width=True)
            
            # ç›¸å…³æ€§åˆ†æ
            correlation = df[col1_name].corr(df[col2_name])
            st.metric("ç›¸å…³ç³»æ•°", f"{correlation:.3f}")
            
            # æ•£ç‚¹å›¾
            fig_scatter = px.scatter(
                df,
                x=col1_name,
                y=col2_name,
                title=f"{col1_name} vs {col2_name}",
                trendline="ols"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
    
    elif comparison_type == "åˆ†ç»„å¯¹æ¯”":
        st.markdown("### ğŸ‘¥ åˆ†ç»„æ•°æ®å¯¹æ¯”")
        
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if not categorical_cols or not numeric_cols:
            st.warning("âš ï¸ éœ€è¦è‡³å°‘1ä¸ªåˆ†ç±»åˆ—å’Œ1ä¸ªæ•°å€¼åˆ—è¿›è¡Œåˆ†ç»„å¯¹æ¯”")
            return
        
        group_col = st.selectbox("é€‰æ‹©åˆ†ç»„åˆ—", categorical_cols)
        value_col = st.selectbox("é€‰æ‹©æ•°å€¼åˆ—", numeric_cols)
        
        if st.button("å¼€å§‹åˆ†ç»„å¯¹æ¯”"):
            # åˆ†ç»„ç»Ÿè®¡
            group_stats = df.groupby(group_col)[value_col].agg([
                'count', 'mean', 'median', 'std', 'min', 'max'
            ]).round(2)
            
            st.markdown("#### åˆ†ç»„ç»Ÿè®¡")
            st.dataframe(group_stats)
            
            # ç®±çº¿å›¾å¯¹æ¯”
            fig_box = px.box(
                df,
                x=group_col,
                y=value_col,
                title=f"{value_col} æŒ‰ {group_col} åˆ†ç»„å¯¹æ¯”"
            )
            st.plotly_chart(fig_box, use_container_width=True)
            
            # å°æç´å›¾
            fig_violin = px.violin(
                df,
                x=group_col,
                y=value_col,
                title=f"{value_col} åˆ†å¸ƒå¯¹æ¯”ï¼ˆå°æç´å›¾ï¼‰"
            )
            st.plotly_chart(fig_violin, use_container_width=True)
            
            # æ–¹å·®åˆ†æï¼ˆå¦‚æœåˆ†ç»„æ•°é‡åˆé€‚ï¼‰
            groups = [group[value_col].dropna() for name, group in df.groupby(group_col)]
            
            if len(groups) >= 2:
                try:
                    f_stat, p_value = stats.f_oneway(*groups)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Fç»Ÿè®¡é‡", f"{f_stat:.3f}")
                    with col2:
                        st.metric("på€¼", f"{p_value:.3f}")
                    
                    if p_value < 0.05:
                        st.success("âœ… å„ç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ˆp < 0.05ï¼‰")
                    else:
                        st.info("â„¹ï¸ å„ç»„é—´æ— æ˜¾è‘—å·®å¼‚ï¼ˆp >= 0.05ï¼‰")
                        
                except Exception as e:
                    st.warning(f"æ–¹å·®åˆ†æå¤±è´¥: {str(e)}")


def data_import_export_section(df: pd.DataFrame):
    """æ•°æ®å¯¼å…¥å¯¼å‡ºåŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">æ•°æ®å¯¼å…¥å¯¼å‡º</h2>', unsafe_allow_html=True)
    
    operation_type = st.selectbox(
        "é€‰æ‹©æ“ä½œç±»å‹",
        ["æ•°æ®å¯¼å‡º", "æ ¼å¼è½¬æ¢", "æ•°æ®åˆå¹¶", "æ•°æ®æ‹†åˆ†", "æ‰¹é‡å¤„ç†"]
    )
    
    if operation_type == "æ•°æ®å¯¼å‡º":
        st.markdown("### æ•°æ®å¯¼å‡º")
        
        export_format = st.selectbox(
            "é€‰æ‹©å¯¼å‡ºæ ¼å¼",
            ["CSV", "Excel (XLSX)", "JSON", "HTML", "Parquet"]
        )
        
        # å¯¼å‡ºé€‰é¡¹
        col1, col2 = st.columns(2)
        
        with col1:
            include_index = st.checkbox("åŒ…å«ç´¢å¼•", value=False)
            selected_columns = st.multiselect(
                "é€‰æ‹©è¦å¯¼å‡ºçš„åˆ— (ç•™ç©ºè¡¨ç¤ºå…¨éƒ¨)",
                df.columns.tolist()
            )
        
        with col2:
            if len(df) > 1000:
                export_rows = st.number_input(
                    "å¯¼å‡ºè¡Œæ•° (0è¡¨ç¤ºå…¨éƒ¨)",
                    min_value=0,
                    max_value=len(df),
                    value=1000
                )
            else:
                export_rows = len(df)
        
        # å‡†å¤‡å¯¼å‡ºæ•°æ®
        export_df = df.copy()
        
        if selected_columns:
            export_df = export_df[selected_columns]
        
        if export_rows > 0 and export_rows < len(export_df):
            export_df = export_df.head(export_rows)
        
        # æ˜¾ç¤ºé¢„è§ˆ
        st.markdown("#### å¯¼å‡ºé¢„è§ˆ")
        st.info(f"å°†å¯¼å‡º {len(export_df)} è¡Œ Ã— {len(export_df.columns)} åˆ—æ•°æ®")
        st.dataframe(export_df.head(5))
        
        # ç”Ÿæˆä¸‹è½½æŒ‰é’®
        if export_format == "CSV":
            data = export_df.to_csv(index=include_index, encoding='utf-8-sig')
            filename = "exported_data.csv"
            mime_type = "text/csv"
        
        elif export_format == "Excel (XLSX)":
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                export_df.to_excel(writer, index=include_index, sheet_name='Data')
            data = buffer.getvalue()
            filename = "exported_data.xlsx"
            mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        
        elif export_format == "JSON":
            data = export_df.to_json(orient='records', force_ascii=False, indent=2)
            filename = "exported_data.json"
            mime_type = "application/json"
        
        elif export_format == "HTML":
            data = export_df.to_html(index=include_index, escape=False)
            filename = "exported_data.html"
            mime_type = "text/html"
        
        elif export_format == "Parquet":
            buffer = BytesIO()
            export_df.to_parquet(buffer, index=include_index)
            data = buffer.getvalue()
            filename = "exported_data.parquet"
            mime_type = "application/octet-stream"
        
        st.download_button(
            label=f"ä¸‹è½½ {export_format} æ–‡ä»¶",
            data=data,
            file_name=filename,
            mime=mime_type
        )
    
    elif operation_type == "æ ¼å¼è½¬æ¢":
        st.markdown("### æ ¼å¼è½¬æ¢")
        
        st.info("ğŸ’¡ æ”¯æŒåœ¨ä¸åŒæ•°æ®æ ¼å¼ä¹‹é—´è½¬æ¢")
        
        # æ•°æ®ç±»å‹è½¬æ¢
        st.markdown("#### æ•°æ®ç±»å‹è½¬æ¢")
        
        conversion_options = {
            "æ•°å€¼è½¬æ–‡æœ¬": "å°†æ•°å€¼åˆ—è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼",
            "æ–‡æœ¬è½¬æ•°å€¼": "å°†æ–‡æœ¬åˆ—è½¬æ¢ä¸ºæ•°å€¼æ ¼å¼",
            "æ—¥æœŸæ ¼å¼åŒ–": "æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼",
            "å¸ƒå°”è½¬æ¢": "è½¬æ¢ä¸ºå¸ƒå°”å€¼"
        }
        
        conversion_type = st.selectbox(
            "é€‰æ‹©è½¬æ¢ç±»å‹",
            list(conversion_options.keys())
        )
        
        st.info(conversion_options[conversion_type])
        
        if conversion_type == "æ•°å€¼è½¬æ–‡æœ¬":
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                selected_col = st.selectbox("é€‰æ‹©æ•°å€¼åˆ—", numeric_cols)
                
                if st.button("æ‰§è¡Œè½¬æ¢"):
                    df_converted = df.copy()
                    df_converted[selected_col] = df_converted[selected_col].astype(str)
                    
                    st.success(f"âœ… å·²å°† {selected_col} è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼")
                    
                    # æ˜¾ç¤ºè½¬æ¢ç»“æœ
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("#### è½¬æ¢å‰")
                        st.write(f"æ•°æ®ç±»å‹: {df[selected_col].dtype}")
                        st.dataframe(df[[selected_col]].head())
                    
                    with col2:
                        st.markdown("#### è½¬æ¢å")
                        st.write(f"æ•°æ®ç±»å‹: {df_converted[selected_col].dtype}")
                        st.dataframe(df_converted[[selected_col]].head())
                    
                    # ä¸‹è½½è½¬æ¢åçš„æ•°æ®
                    csv = df_converted.to_csv(index=False)
                    st.download_button(
                        label="ä¸‹è½½è½¬æ¢åçš„æ•°æ®",
                        data=csv,
                        file_name="converted_data.csv",
                        mime="text/csv"
                    )
        
        elif conversion_type == "æ–‡æœ¬è½¬æ•°å€¼":
            text_cols = df.select_dtypes(include=['object']).columns.tolist()
            if text_cols:
                selected_col = st.selectbox("é€‰æ‹©æ–‡æœ¬åˆ—", text_cols)
                
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥è½¬æ¢ä¸ºæ•°å€¼
                sample_data = df[selected_col].dropna().head(10)
                st.markdown("#### æ•°æ®é¢„è§ˆ")
                st.dataframe(sample_data)
                
                if st.button("æ‰§è¡Œè½¬æ¢"):
                    try:
                        df_converted = df.copy()
                        df_converted[selected_col] = pd.to_numeric(df_converted[selected_col], errors='coerce')
                        
                        # ç»Ÿè®¡è½¬æ¢ç»“æœ
                        null_count = df_converted[selected_col].isnull().sum()
                        success_rate = (len(df_converted) - null_count) / len(df_converted) * 100
                        
                        st.success(f"âœ… è½¬æ¢å®Œæˆï¼ŒæˆåŠŸç‡: {success_rate:.1f}%")
                        
                        if null_count > 0:
                            st.warning(f"âš ï¸ æœ‰ {null_count} ä¸ªå€¼æ— æ³•è½¬æ¢ï¼Œå·²è®¾ä¸º NaN")
                        
                        # æ˜¾ç¤ºè½¬æ¢ç»“æœ
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown("#### è½¬æ¢å‰")
                            st.write(f"æ•°æ®ç±»å‹: {df[selected_col].dtype}")
                            st.dataframe(df[[selected_col]].head())
                        
                        with col2:
                            st.markdown("#### è½¬æ¢å")
                            st.write(f"æ•°æ®ç±»å‹: {df_converted[selected_col].dtype}")
                            st.dataframe(df_converted[[selected_col]].head())
                        
                        # ä¸‹è½½è½¬æ¢åçš„æ•°æ®
                        csv = df_converted.to_csv(index=False)
                        st.download_button(
                            label="ä¸‹è½½è½¬æ¢åçš„æ•°æ®",
                            data=csv,
                            file_name="converted_data.csv",
                            mime="text/csv"
                        )
                        
                    except Exception as e:
                        st.error(f"âŒ è½¬æ¢å¤±è´¥: {str(e)}")


def data_validation_section(df: pd.DataFrame):
    """æ•°æ®éªŒè¯åŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">æ•°æ®éªŒè¯</h2>', unsafe_allow_html=True)
    
    validation_type = st.selectbox(
        "é€‰æ‹©éªŒè¯ç±»å‹",
        ["æ•°æ®å®Œæ•´æ€§æ£€æŸ¥", "æ•°æ®æ ¼å¼éªŒè¯", "ä¸šåŠ¡è§„åˆ™éªŒè¯", "é‡å¤å€¼æ£€æµ‹", "å¼‚å¸¸å€¼æ£€æµ‹"]
    )
    
    if validation_type == "æ•°æ®å®Œæ•´æ€§æ£€æŸ¥":
        st.markdown("### æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
        
        # ç¼ºå¤±å€¼åˆ†æ
        missing_data = df.isnull().sum()
        missing_percent = (missing_data / len(df) * 100).round(2)
        
        # åˆ›å»ºç¼ºå¤±å€¼æŠ¥å‘Š
        missing_report = pd.DataFrame({
            'åˆ—å': missing_data.index,
            'ç¼ºå¤±å€¼æ•°é‡': missing_data.values,
            'ç¼ºå¤±å€¼æ¯”ä¾‹(%)': missing_percent.values,
            'æ•°æ®ç±»å‹': [str(df[col].dtype) for col in missing_data.index]
        })
        
        missing_report = missing_report[missing_report['ç¼ºå¤±å€¼æ•°é‡'] > 0].sort_values('ç¼ºå¤±å€¼æ•°é‡', ascending=False)
        
        if len(missing_report) > 0:
            st.markdown("#### âŒ å‘ç°ç¼ºå¤±å€¼")
            st.dataframe(missing_report, use_container_width=True)
            
            # å¯è§†åŒ–ç¼ºå¤±å€¼
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=missing_report['åˆ—å'],
                y=missing_report['ç¼ºå¤±å€¼æ¯”ä¾‹(%)'],
                name='ç¼ºå¤±å€¼æ¯”ä¾‹',
                marker_color='red'
            ))
            
            fig.update_layout(
                title="å„åˆ—ç¼ºå¤±å€¼æ¯”ä¾‹",
                xaxis_title="åˆ—å",
                yaxis_title="ç¼ºå¤±å€¼æ¯”ä¾‹ (%)",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # å¤„ç†å»ºè®®
            st.markdown("#### ğŸ’¡ å¤„ç†å»ºè®®")
            for _, row in missing_report.iterrows():
                col_name = row['åˆ—å']
                missing_pct = row['ç¼ºå¤±å€¼æ¯”ä¾‹(%)']
                
                if missing_pct > 50:
                    suggestion = "è€ƒè™‘åˆ é™¤è¯¥åˆ—æˆ–å¯»æ‰¾æ›¿ä»£æ•°æ®æº"
                    color = "ğŸ”´"
                elif missing_pct > 20:
                    suggestion = "è€ƒè™‘ä½¿ç”¨æ’å€¼æˆ–å‡å€¼å¡«å……"
                    color = "ğŸŸ¡"
                else:
                    suggestion = "å¯ä»¥åˆ é™¤ç¼ºå¤±è¡Œæˆ–ç®€å•å¡«å……"
                    color = "ğŸŸ¢"
                
                st.write(f"{color} **{col_name}** ({missing_pct}%): {suggestion}")
        
        else:
            st.success("âœ… æ•°æ®å®Œæ•´æ€§è‰¯å¥½ï¼Œæœªå‘ç°ç¼ºå¤±å€¼")
        
        # æ•°æ®ç±»å‹ä¸€è‡´æ€§æ£€æŸ¥
        st.markdown("#### æ•°æ®ç±»å‹åˆ†æ")
        
        dtype_summary = pd.DataFrame({
            'åˆ—å': df.columns,
            'æ•°æ®ç±»å‹': [str(dtype) for dtype in df.dtypes],
            'å”¯ä¸€å€¼æ•°é‡': [df[col].nunique() for col in df.columns],
            'æ ·æœ¬å€¼': [str(df[col].dropna().iloc[0]) if len(df[col].dropna()) > 0 else 'N/A' for col in df.columns]
        })
        
        st.dataframe(dtype_summary, use_container_width=True)
    
    elif validation_type == "é‡å¤å€¼æ£€æµ‹":
        st.markdown("### é‡å¤å€¼æ£€æµ‹")
        
        # å®Œå…¨é‡å¤è¡Œæ£€æµ‹
        duplicate_rows = df.duplicated()
        duplicate_count = duplicate_rows.sum()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ€»è¡Œæ•°", len(df))
        with col2:
            st.metric("é‡å¤è¡Œæ•°", duplicate_count)
        with col3:
            duplicate_rate = (duplicate_count / len(df) * 100) if len(df) > 0 else 0
            st.metric("é‡å¤ç‡", f"{duplicate_rate:.2f}%")
        
        if duplicate_count > 0:
            st.warning(f"âš ï¸ å‘ç° {duplicate_count} è¡Œå®Œå…¨é‡å¤çš„æ•°æ®")
            
            # æ˜¾ç¤ºé‡å¤è¡Œ
            st.markdown("#### é‡å¤è¡Œé¢„è§ˆ")
            duplicate_data = df[duplicate_rows]
            st.dataframe(duplicate_data.head(10))
            
            # å¤„ç†é€‰é¡¹
            if st.button("åˆ é™¤é‡å¤è¡Œ"):
                df_cleaned = df.drop_duplicates()
                removed_count = len(df) - len(df_cleaned)
                
                st.success(f"âœ… å·²åˆ é™¤ {removed_count} è¡Œé‡å¤æ•°æ®")
                
                # æ˜¾ç¤ºæ¸…ç†åçš„ç»Ÿè®¡
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("æ¸…ç†å‰è¡Œæ•°", len(df))
                with col2:
                    st.metric("æ¸…ç†åè¡Œæ•°", len(df_cleaned))
                
                # ä¸‹è½½æ¸…ç†åçš„æ•°æ®
                csv = df_cleaned.to_csv(index=False)
                st.download_button(
                    label="ä¸‹è½½å»é‡åçš„æ•°æ®",
                    data=csv,
                    file_name="deduplicated_data.csv",
                    mime="text/csv"
                )
        else:
            st.success("âœ… æœªå‘ç°å®Œå…¨é‡å¤çš„è¡Œ")
        
        # æŒ‰ç‰¹å®šåˆ—æ£€æµ‹é‡å¤
        st.markdown("#### æŒ‰åˆ—æ£€æµ‹é‡å¤")
        
        selected_columns = st.multiselect(
            "é€‰æ‹©è¦æ£€æŸ¥é‡å¤çš„åˆ—",
            df.columns.tolist(),
            help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªåˆ—æ¥æ£€æµ‹åŸºäºè¿™äº›åˆ—çš„é‡å¤å€¼"
        )
        
        if selected_columns:
            column_duplicates = df.duplicated(subset=selected_columns)
            column_duplicate_count = column_duplicates.sum()
            
            st.info(f"åŸºäºé€‰å®šåˆ—çš„é‡å¤è¡Œæ•°: {column_duplicate_count}")
            
            if column_duplicate_count > 0:
                st.dataframe(df[column_duplicates][selected_columns].head(10))